{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word Sense Disambiguation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tecXworld/Natural-Language-Processing/blob/main/Word_Sense_Disambiguation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnBkzMtTMD3M"
      },
      "source": [
        "import nltk\n",
        "nltk.download('all')\n",
        "import codecs\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO66iHheJsnX",
        "outputId": "fb637ffa-5713-4c09-bceb-3ff163dc7f19"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSrALGZeOF9H"
      },
      "source": [
        "def simpleFilter(sentence):\n",
        "\n",
        "    filtered_sent = []\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    words = word_tokenize(sentence)\n",
        "\n",
        "    for w in words:\n",
        "            if w not in stop_words:\n",
        "                    filtered_sent.append(lemmatizer.lemmatize(w))\n",
        "\n",
        "    return filtered_sent"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIEqd6VIOYLW"
      },
      "source": [
        "def simlilarityCheck(word1, word2):\n",
        "\n",
        "\tword1 = word1 + \".n.01\"\n",
        "\tword2 = word2 + \".n.01\"\n",
        "\ttry:\n",
        "\t\tw1 = wordnet.synset(word1)\n",
        "\t\tw2 = wordnet.synset(word2)\n",
        "\n",
        "\t\treturn w1.wup_similarity(w2)\n",
        "\n",
        "\texcept:\n",
        "\t\treturn 0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTzc7W1-OhsX"
      },
      "source": [
        "def synonymsCreator(word):\n",
        "\tsynonyms = []\n",
        "\n",
        "\tfor syn in wordnet.synsets(word):\n",
        "\t\tfor i in syn.lemmas():\n",
        "\t\t\tsynonyms.append(i.name())\n",
        "\n",
        "\treturn synonyms"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcgzi3VJOmvn"
      },
      "source": [
        "# Remove Stop Words . Word Stemming . Return new tokenised list.\n",
        "def filteredSentence(sentence):\n",
        "\n",
        "\tfiltered_sent = []\n",
        "\tlemmatizer = WordNetLemmatizer()   #lemmatizes the words\n",
        "\tps = PorterStemmer()    #stemmer stems the root of the word.\n",
        "\n",
        "\tstop_words = set(stopwords.words(\"english\"))\n",
        "\twords = word_tokenize(sentence)\n",
        "\n",
        "\tfor w in words:\n",
        "        \tif w not in stop_words:\n",
        "                \tfiltered_sent.append(lemmatizer.lemmatize(ps.stem(w)))\n",
        "                \tfor i in synonymsCreator(w):\n",
        "                \t\tfiltered_sent.append(i)\n",
        "\treturn filtered_sent"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OHs9Sv0OrVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5deb0dd1-3c7e-4581-d35d-d20ef25fdd52"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "\tcricfile = codecs.open(\"/content/gdrive/MyDrive/cricketbat.txt\", 'r', \"utf-8\")\n",
        "\tsent2 = cricfile.read().lower()\n",
        "\tvampirefile = codecs.open(\"/content/gdrive/MyDrive/vampirebat.txt\", 'r', 'utf-8')\n",
        "\tsent1 = vampirefile.read().lower()\n",
        "\tsent3 = \"start\"\n",
        "\n",
        "\n",
        "\twhile(sent3 != \"end\"):\n",
        "\n",
        "\t\tsent3 = input(\"Enter Query: \").lower()\n",
        "\n",
        "\t\t\n",
        "\t\tsent31_similarity = 0\n",
        "\t\tsent32_similarity = 0\n",
        "\n",
        "\t\tfiltered_sent1 = simpleFilter(sent1)\n",
        "\t\tfiltered_sent2 = simpleFilter(sent2)\n",
        "\t\tfiltered_sent3 = simpleFilter(sent3)\n",
        "\n",
        "\t\tfor i in filtered_sent3:\n",
        "\n",
        "\t\t\tfor j in filtered_sent1:\n",
        "\t\t\t\tsent31_similarity = sent31_similarity + simlilarityCheck(i,j)\n",
        "\n",
        "\t\t\tfor j in filtered_sent2:\n",
        "\t\t\t\tsent32_similarity = sent32_similarity + simlilarityCheck(i,j)\n",
        "\n",
        "\n",
        "\t\tfiltered_sent1 = filteredSentence(sent1)\n",
        "\t\tfiltered_sent2 = filteredSentence(sent2)\n",
        "\t\tfiltered_sent3 = filteredSentence(sent3)\n",
        "\n",
        "\t\tsent1_count = 0\n",
        "\t\tsent2_count = 0\n",
        "\n",
        "\t\tfor i in filtered_sent3:\n",
        "\n",
        "\t\t\tfor j in filtered_sent1:\n",
        "\n",
        "\t\t\t\tif(i==j):\n",
        "\t\t\t\t\tsent1_count = sent1_count + 1\n",
        "\n",
        "\t\t\tfor j in filtered_sent2:\n",
        "\t\t\t\tif(i==j):\n",
        "\t\t\t\t\tsent2_count = sent2_count + 1\n",
        "\n",
        "\t\tif((sent1_count + sent31_similarity)>(sent2_count+sent32_similarity)):\n",
        "\t\t\tprint(\"Mammal Bat\")\n",
        "\t\telse:\n",
        "\t\t\tprint(\"Cricket Bat\")\n",
        "\n",
        "\t\t#-----------------------------------------------\n",
        "\n",
        "\t\t#sen1: any of various nocturnal flying mammals of the order Chiroptera, having membranous wings that extend from the forelimbs to the hind limbs or tail and anatomical adaptations for echolocation, by which they navigate and hunt prey.\n",
        "\t\t#sen 2: a cricket wooden bat is used for playing criket. it is rectangular in shape and has handle and is made of wood or plastic and is used by cricket players.\n",
        "\tprint(\"\\nTERMINATED\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter Query: Which bat can fly\n",
            "Mammal Bat\n",
            "Enter Query: Which bat has wings\n",
            "Mammal Bat\n",
            "Enter Query: Which bat is strong\n",
            "Cricket Bat\n",
            "Enter Query: end\n",
            "Mammal Bat\n",
            "\n",
            "TERMINATED\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}