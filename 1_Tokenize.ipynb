{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "1-Tokenize.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tecXworld/Natural-Language-Processing/blob/main/1_Tokenize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1wC2RPibayo"
      },
      "source": [
        "import nltk\n",
        "nltk.download('all')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKVHeFOHbay1"
      },
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSiCHg51bay3"
      },
      "source": [
        "#string\n",
        "mynlp = 'Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The result is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39uTII-Pbay4",
        "outputId": "c33c1e0d-0ef6-46e2-d799-8653cf67b6a7"
      },
      "source": [
        "#tokenizing\n",
        "mynlp_token = word_tokenize(mynlp)\n",
        "mynlp_token"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " '(',\n",
              " 'NLP',\n",
              " ')',\n",
              " 'is',\n",
              " 'a',\n",
              " 'subfield',\n",
              " 'of',\n",
              " 'linguistics',\n",
              " ',',\n",
              " 'computer',\n",
              " 'science',\n",
              " ',',\n",
              " 'and',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'concerned',\n",
              " 'with',\n",
              " 'the',\n",
              " 'interactions',\n",
              " 'between',\n",
              " 'computers',\n",
              " 'and',\n",
              " 'human',\n",
              " 'language',\n",
              " ',',\n",
              " 'in',\n",
              " 'particular',\n",
              " 'how',\n",
              " 'to',\n",
              " 'program',\n",
              " 'computers',\n",
              " 'to',\n",
              " 'process',\n",
              " 'and',\n",
              " 'analyze',\n",
              " 'large',\n",
              " 'amounts',\n",
              " 'of',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'data',\n",
              " '.',\n",
              " 'The',\n",
              " 'result',\n",
              " 'is',\n",
              " 'a',\n",
              " 'computer',\n",
              " 'capable',\n",
              " 'of',\n",
              " '``',\n",
              " 'understanding',\n",
              " \"''\",\n",
              " 'the',\n",
              " 'contents',\n",
              " 'of',\n",
              " 'documents',\n",
              " ',',\n",
              " 'including',\n",
              " 'the',\n",
              " 'contextual',\n",
              " 'nuances',\n",
              " 'of',\n",
              " 'the',\n",
              " 'language',\n",
              " 'within',\n",
              " 'them',\n",
              " '.',\n",
              " 'The',\n",
              " 'technology',\n",
              " 'can',\n",
              " 'then',\n",
              " 'accurately',\n",
              " 'extract',\n",
              " 'information',\n",
              " 'and',\n",
              " 'insights',\n",
              " 'contained',\n",
              " 'in',\n",
              " 'the',\n",
              " 'documents',\n",
              " 'as',\n",
              " 'well',\n",
              " 'as',\n",
              " 'categorize',\n",
              " 'and',\n",
              " 'organize',\n",
              " 'the',\n",
              " 'documents',\n",
              " 'themselves',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5zDG-PzbazA",
        "outputId": "82b0bde2-6ee3-4eca-9464-37d58324c32a"
      },
      "source": [
        "#checking the type and number of tokens\n",
        "type(mynlp_token), len(mynlp_token)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 93)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LCaPoi-bazC"
      },
      "source": [
        "#frequency of tokens\n",
        "from nltk.probability import FreqDist\n",
        "fdist = FreqDist()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNjjhi72bazD",
        "outputId": "8cf6d619-71e5-43e2-c81a-9e5ca5203578"
      },
      "source": [
        "for i in mynlp_token:\n",
        "    fdist[i] = fdist[i]+1\n",
        "fdist\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({\"''\": 1,\n",
              "          '(': 1,\n",
              "          ')': 1,\n",
              "          ',': 4,\n",
              "          '.': 3,\n",
              "          'NLP': 1,\n",
              "          'Natural': 1,\n",
              "          'The': 2,\n",
              "          '``': 1,\n",
              "          'a': 2,\n",
              "          'accurately': 1,\n",
              "          'amounts': 1,\n",
              "          'analyze': 1,\n",
              "          'and': 5,\n",
              "          'artificial': 1,\n",
              "          'as': 2,\n",
              "          'between': 1,\n",
              "          'can': 1,\n",
              "          'capable': 1,\n",
              "          'categorize': 1,\n",
              "          'computer': 2,\n",
              "          'computers': 2,\n",
              "          'concerned': 1,\n",
              "          'contained': 1,\n",
              "          'contents': 1,\n",
              "          'contextual': 1,\n",
              "          'data': 1,\n",
              "          'documents': 3,\n",
              "          'extract': 1,\n",
              "          'how': 1,\n",
              "          'human': 1,\n",
              "          'in': 2,\n",
              "          'including': 1,\n",
              "          'information': 1,\n",
              "          'insights': 1,\n",
              "          'intelligence': 1,\n",
              "          'interactions': 1,\n",
              "          'is': 2,\n",
              "          'language': 4,\n",
              "          'large': 1,\n",
              "          'linguistics': 1,\n",
              "          'natural': 1,\n",
              "          'nuances': 1,\n",
              "          'of': 5,\n",
              "          'organize': 1,\n",
              "          'particular': 1,\n",
              "          'process': 1,\n",
              "          'processing': 1,\n",
              "          'program': 1,\n",
              "          'result': 1,\n",
              "          'science': 1,\n",
              "          'subfield': 1,\n",
              "          'technology': 1,\n",
              "          'the': 6,\n",
              "          'them': 1,\n",
              "          'themselves': 1,\n",
              "          'then': 1,\n",
              "          'to': 2,\n",
              "          'understanding': 1,\n",
              "          'well': 1,\n",
              "          'with': 1,\n",
              "          'within': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE5atdckbazH",
        "outputId": "18df2e10-6eb3-4611-9cbe-5dd101c5eb00"
      },
      "source": [
        "#ten most common tokens\n",
        "top_10=fdist.most_common(10)\n",
        "top_10"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 6),\n",
              " ('of', 5),\n",
              " ('and', 5),\n",
              " ('language', 4),\n",
              " (',', 4),\n",
              " ('.', 3),\n",
              " ('documents', 3),\n",
              " ('is', 2),\n",
              " ('a', 2),\n",
              " ('computer', 2)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}